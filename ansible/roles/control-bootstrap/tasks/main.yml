---
  - name: Wait for SSH
    wait_for:
      port: 22
    vars:
      ansible_connection: local

  - name: Wait for k8s utilities to be installed
    wait_for:
      path: /etc/kubernetes/manifests

  - name: Copy keepalived template config to control plane nodes
    become: true
    template:
      src: keepalived.conf.j2
      dest: /usr/local/etc/keepalived.conf
      owner: root
      group: root
      mode: 0640
    vars:
      STATE: "{{ 'MASTER' if ansible_facts['default_ipv4']['address'] == '10.17.3.2' else 'BACKUP'}}"
      PRIORITY: "{{ '101' if ansible_facts['default_ipv4']['address'] == '10.17.3.2' else '100'}}"

  - name: Copy keepalived check to control plane nodes
    become: true
    template:
      src: check_apiserver.sh.j2
      dest: /usr/local/etc/check_apiserver.sh
      owner: root
      group: root
      mode: 0750

  - name: Copy keepalived k8s manifest to control plane nodes
    become: true
    copy:
      src: keepalived.yaml
      dest: /etc/kubernetes/manifests/keepalived.yaml
      owner: root
      group: root
      mode: 0640

  - name: Copy haproxy template config to control plane nodes
    become: true
    template:
      src: haproxy.cfg.j2
      dest: /usr/local/etc/haproxy.cfg
      owner: root
      group: root
      mode: 0750
    # vars:
    #   HOST2_ID: k8s-controllers-2
    #   HOST3_ID: k8s-controllers-3
    #   HOST4_ID: k8s-controllers-4
    #   HOST2_ADDRESS: 10.17.3.2
    #   HOST3_ADDRESS: 10.17.3.3
    #   HOST4_ADDRESS: 10.17.3.4

  - name: Copy haproxy k8s manifest to control plane
    become: true
    template:
      src: haproxy.yaml.j2
      dest: /etc/kubernetes/manifests/haproxy.yaml
      owner: root
      group: root
      mode: 0640

  - name: Initialize the Kubernetes cluster using kubeadm
    become: true
    command: kubeadm init --control-plane-endpoint '10.17.3.254:8080' --upload-certs --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests
    when: ansible_facts['default_ipv4']['address'] == "10.17.3.2"

  - name: Generate a control plane certificate for HA nodes
    become: true
    shell: kubeadm init phase upload-certs --upload-certs 2> /dev/null|tail -n 1
    register: join_certificate
    when: ansible_facts['default_ipv4']['address'] == "10.17.3.2"

  - name: Initialize the Kubernetes cluster using kubeadm
    become: true
    shell: kubeadm token create --print-join-command --certificate-key {{join_certificate.stdout}} | echo "$(cat -) --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests"
    register: join_command
    when: ansible_facts['default_ipv4']['address'] == "10.17.3.2"

  - name: Set join control plane command
    set_fact:
      join_control_plane_command: '{{join_command.stdout}}'
    when: ansible_facts['default_ipv4']['address'] == "10.17.3.2"

  - name: Wait for kube api to be available, then set up CNI overlay
    wait_for:
      port: 6443
    when: ansible_facts['default_ipv4']['address'] == "10.17.3.2"

  - name: Install cilium pod network
    become: true
    command: kubectl --kubeconfig /etc/kubernetes/admin.conf create -f https://raw.githubusercontent.com/cilium/cilium/v1.8/install/kubernetes/quick-install.yaml
    when: ansible_facts['default_ipv4']['address'] == "10.17.3.2"

  - name: Wait for cilium
    wait_for:
      delay: 60

  - name: Join the node to the cluster
    become: true
    shell: "{{ hostvars['10.17.3.2'].join_control_plane_command }}"
    when: ansible_facts['default_ipv4']['address'] != "10.17.3.2"

  - name: Setup kubeconfig
    become: true
    command: "{{ item }}"
    with_items:
     - mkdir -p /root/.kube
     - cp -i /etc/kubernetes/admin.conf /root/.kube/config
